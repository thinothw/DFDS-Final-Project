{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEEUHxq1TI14ST/+y6+bpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7f1b9d27eba498dbd1f40a23021564a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a89b0cd9bcd4d66b3927c266185ec0f",
              "IPY_MODEL_55858bb35fb7427d8b6f0b0a0778a71b",
              "IPY_MODEL_2196d85cafa74285878241360e972cc9"
            ],
            "layout": "IPY_MODEL_34aa22fde8f1401d994d0d6bcad05278"
          }
        },
        "1a89b0cd9bcd4d66b3927c266185ec0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4468bf337e7438eb580ad4de5be27cd",
            "placeholder": "​",
            "style": "IPY_MODEL_8f3b7c47950641e19a2ed744c464ca63",
            "value": "Downloading readme: "
          }
        },
        "55858bb35fb7427d8b6f0b0a0778a71b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9d21fb9ad5d46018ddbd8dacd2c6bcb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5aef3a24e2054c56b9703c362ca80b82",
            "value": 1
          }
        },
        "2196d85cafa74285878241360e972cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3462d4b482cb488f88ed1c33dd042fd0",
            "placeholder": "​",
            "style": "IPY_MODEL_c056938f2966495db102a238c584db62",
            "value": " 6.63k/? [00:00&lt;00:00, 402kB/s]"
          }
        },
        "34aa22fde8f1401d994d0d6bcad05278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4468bf337e7438eb580ad4de5be27cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3b7c47950641e19a2ed744c464ca63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9d21fb9ad5d46018ddbd8dacd2c6bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5aef3a24e2054c56b9703c362ca80b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3462d4b482cb488f88ed1c33dd042fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c056938f2966495db102a238c584db62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0cd8ca6fce45cbadba586bb98ca66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa104e960f4c46a1be8035f034b418fe",
              "IPY_MODEL_0f252a45e7db4c739a9957773fd3377d",
              "IPY_MODEL_bf6665af9b7e40128ce6c86e20068fa2"
            ],
            "layout": "IPY_MODEL_193d160514e843a58f072457856b92a1"
          }
        },
        "aa104e960f4c46a1be8035f034b418fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53304587c0c3443d8bc2dbf02bdd7352",
            "placeholder": "​",
            "style": "IPY_MODEL_e478e06f2979449cb6e7339905b3a96f",
            "value": "Resolving data files: 100%"
          }
        },
        "0f252a45e7db4c739a9957773fd3377d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc1387d348d04876875e366782ea9d87",
            "max": 206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c08327768d41e9a3897f1495d200b2",
            "value": 206
          }
        },
        "bf6665af9b7e40128ce6c86e20068fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18c75c41f33e4d609650835000f3f3d9",
            "placeholder": "​",
            "style": "IPY_MODEL_dc159ac6ffcb4ffdaff4198e6d252cb7",
            "value": " 206/206 [00:00&lt;00:00, 12190.34it/s]"
          }
        },
        "193d160514e843a58f072457856b92a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53304587c0c3443d8bc2dbf02bdd7352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e478e06f2979449cb6e7339905b3a96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc1387d348d04876875e366782ea9d87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c08327768d41e9a3897f1495d200b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18c75c41f33e4d609650835000f3f3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc159ac6ffcb4ffdaff4198e6d252cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c014e714941b422383a1ada48ec0d674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c535a0dea3ad4e0c8ff81f3d720fd3f2",
              "IPY_MODEL_c49baca9b7bb4d2ab17c7020005684c4",
              "IPY_MODEL_3f7ea3b4c14f4f7baf2ef32f19038b22"
            ],
            "layout": "IPY_MODEL_b3cfa70a98ac43229374bef72eac2d38"
          }
        },
        "c535a0dea3ad4e0c8ff81f3d720fd3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc498bea4d54df2af6336774c88906b",
            "placeholder": "​",
            "style": "IPY_MODEL_e7ba2fba9c06409cad34d4d5c41e1ca7",
            "value": "Resolving data files: 100%"
          }
        },
        "c49baca9b7bb4d2ab17c7020005684c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae34da16e56d4d1687d84743f2a754bd",
            "max": 206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52ec0ff595574ea6a9dbfb77a4c2deff",
            "value": 206
          }
        },
        "3f7ea3b4c14f4f7baf2ef32f19038b22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51932a4010264a4292ea6aafdb382b34",
            "placeholder": "​",
            "style": "IPY_MODEL_0f90ba5dbb984c968c4c6a723cb98b8c",
            "value": " 206/206 [00:00&lt;00:00, 8804.02it/s]"
          }
        },
        "b3cfa70a98ac43229374bef72eac2d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc498bea4d54df2af6336774c88906b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ba2fba9c06409cad34d4d5c41e1ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae34da16e56d4d1687d84743f2a754bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ec0ff595574ea6a9dbfb77a4c2deff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51932a4010264a4292ea6aafdb382b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f90ba5dbb984c968c4c6a723cb98b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinothw/DFDS-Final-Project/blob/feature%2Fff%2B%2B---sandbox/Phase01_Sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 01 - Setting up the Environment."
      ],
      "metadata": {
        "id": "1LYZUxSIBwmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install retina-face opencv-python imagehash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGzw_k3yV81R",
        "outputId": "033bac7e-edae-4538-b099-cb18c1adec94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting retina-face\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.13.0.92)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.3.2-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (2.0.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from retina-face) (5.2.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (11.3.0)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from retina-face) (2.19.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.9.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from imagehash) (1.16.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (3.24.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown>=3.10.1->retina-face) (4.67.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (5.29.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (1.78.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=1.9.0->retina-face) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.19.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.10.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=3.10.1->retina-face) (2.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.7.1)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=1.9.0->retina-face) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=1.9.0->retina-face) (0.1.2)\n",
            "Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading ImageHash-4.3.2-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imagehash, retina-face\n",
            "Successfully installed imagehash-4.3.2 retina-face-0.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean, compatible install block\n",
        "!pip uninstall -y numpy -q\n",
        "!pip install -q numpy==1.26.4\n",
        "!pip install -q datasets==2.18.0\n",
        "!pip install -q facenet-pytorch==2.5.3\n",
        "!pip install -q opencv-python==4.8.0.76"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qU98BcPAaCt",
        "outputId": "0960372e-24a1-4386-d933-26daa62d7810"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "xarray-einstats 0.10.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "cupy-cuda12x 14.0.1 requires numpy<2.6,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.38.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INFRASTRUCTURE - Connect to Drive\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"Requesting Google Drive access...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Double check the project folder exists\n",
        "base_path = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K'\n",
        "if os.path.exists(base_path):\n",
        "    print(f\"✅ Connection Stable! Project folder found at: {base_path}\")\n",
        "else:\n",
        "    print(f\"⚠️ Warning: Base path not found. Check your Drive folder name!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR7d0YSeEdd",
        "outputId": "6d45d424-88c3-45c7-ba96-b7eef499c84b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requesting Google Drive access...\n",
            "Mounted at /content/drive\n",
            "✅ Connection Stable! Project folder found at: /content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "import torch\n",
        "print(\"✅ All core imports successful. The environment is stable.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSigR_ApDpHx",
        "outputId": "5359e281-68cc-484c-ca7b-2f0c364a419d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All core imports successful. The environment is stable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 02 - Downloading Data from OpenFake."
      ],
      "metadata": {
        "id": "x3O2BBHTCGPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830,
          "referenced_widgets": [
            "c7f1b9d27eba498dbd1f40a23021564a",
            "1a89b0cd9bcd4d66b3927c266185ec0f",
            "55858bb35fb7427d8b6f0b0a0778a71b",
            "2196d85cafa74285878241360e972cc9",
            "34aa22fde8f1401d994d0d6bcad05278",
            "c4468bf337e7438eb580ad4de5be27cd",
            "8f3b7c47950641e19a2ed744c464ca63",
            "e9d21fb9ad5d46018ddbd8dacd2c6bcb",
            "5aef3a24e2054c56b9703c362ca80b82",
            "3462d4b482cb488f88ed1c33dd042fd0",
            "c056938f2966495db102a238c584db62",
            "5f0cd8ca6fce45cbadba586bb98ca66a",
            "aa104e960f4c46a1be8035f034b418fe",
            "0f252a45e7db4c739a9957773fd3377d",
            "bf6665af9b7e40128ce6c86e20068fa2",
            "193d160514e843a58f072457856b92a1",
            "53304587c0c3443d8bc2dbf02bdd7352",
            "e478e06f2979449cb6e7339905b3a96f",
            "dc1387d348d04876875e366782ea9d87",
            "88c08327768d41e9a3897f1495d200b2",
            "18c75c41f33e4d609650835000f3f3d9",
            "dc159ac6ffcb4ffdaff4198e6d252cb7",
            "c014e714941b422383a1ada48ec0d674",
            "c535a0dea3ad4e0c8ff81f3d720fd3f2",
            "c49baca9b7bb4d2ab17c7020005684c4",
            "3f7ea3b4c14f4f7baf2ef32f19038b22",
            "b3cfa70a98ac43229374bef72eac2d38",
            "2cc498bea4d54df2af6336774c88906b",
            "e7ba2fba9c06409cad34d4d5c41e1ca7",
            "ae34da16e56d4d1687d84743f2a754bd",
            "52ec0ff595574ea6a9dbfb77a4c2deff",
            "51932a4010264a4292ea6aafdb382b34",
            "0f90ba5dbb984c968c4c6a723cb98b8c"
          ]
        },
        "id": "1D0MjdjRokQz",
        "outputId": "8d17b57c-d5a1-4fdc-a513-be6418f47ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Checking GPU availability...\n",
            "Device detected: cpu\n",
            "\n",
            "Setting up high-speed local storage...\n",
            "\n",
            "Connecting to OpenFake dataset stream...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7f1b9d27eba498dbd1f40a23021564a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/206 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f0cd8ca6fce45cbadba586bb98ca66a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/206 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c014e714941b422383a1ada48ec0d674"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset connection successful.\n",
            "\n",
            "Starting MASS DOWNLOAD to local storage (Target: 6000 per class)...\n",
            "  -> Downloaded 1000 / 6000 Fake images...\n",
            "  -> Downloaded 1000 / 6000 Real images...\n",
            "  -> Downloaded 2000 / 6000 Real images...\n",
            "  -> Downloaded 2000 / 6000 Fake images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Downloaded 3000 / 6000 Real images...\n",
            "  -> Downloaded 3000 / 6000 Fake images...\n",
            "  -> Downloaded 4000 / 6000 Fake images...\n",
            "  -> Downloaded 4000 / 6000 Real images...\n",
            "  -> Downloaded 5000 / 6000 Fake images...\n",
            "  -> Downloaded 5000 / 6000 Real images...\n",
            "  -> Downloaded 6000 / 6000 Real images...\n",
            "  -> Downloaded 6000 / 6000 Fake images...\n",
            "\n",
            "=== Download Summary ===\n",
            "Real images saved locally: 6000\n",
            "Fake images saved locally: 6000\n",
            "Save errors: 0\n",
            "\n",
            "Moving files from local storage to Google Drive. Please wait...\n",
            "Cleaning up temporary local files to free space...\n",
            " Mass download, Drive transfer, and cleanup completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Phase 2 - Download.\n",
        "# OpenFake Sandbox Dataset Downloader - 12,000 Images.\n",
        "# Code ran with 0 saved errors!.\n",
        "\n",
        "# 1. Core Imports\n",
        "import os\n",
        "import torch\n",
        "import shutil\n",
        "from datasets import load_dataset\n",
        "\n",
        "# 2. GPU Verification\n",
        "print(\"\\nChecking GPU availability...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device detected: {device}\")\n",
        "\n",
        "# 3. Create High-Speed Local Folders\n",
        "print(\"\\nSetting up high-speed local storage...\")\n",
        "local_base = '/content/temp_raw'\n",
        "local_real = os.path.join(local_base, 'real')\n",
        "local_fake = os.path.join(local_base, 'fake')\n",
        "\n",
        "os.makedirs(local_real, exist_ok=True)\n",
        "os.makedirs(local_fake, exist_ok=True)\n",
        "\n",
        "# 4. Connect to OpenFake Dataset\n",
        "print(\"\\nConnecting to OpenFake dataset stream...\")\n",
        "dataset_name = \"ComplexDataLab/OpenFake\"\n",
        "\n",
        "try:\n",
        "    openfake = load_dataset(dataset_name, split='train', streaming=True)\n",
        "    print(\"Dataset connection successful.\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Dataset loading failed: {e}\")\n",
        "\n",
        "# 5. Download Buffer (6,000 Real + 6,000 Fake)\n",
        "TARGET_BUFFER = 6000\n",
        "real_count = 0\n",
        "fake_count = 0\n",
        "save_errors = 0\n",
        "max_iterations = 80000\n",
        "iteration_counter = 0\n",
        "\n",
        "print(f\"\\nStarting MASS DOWNLOAD to local storage (Target: {TARGET_BUFFER} per class)...\")\n",
        "\n",
        "for item in openfake:\n",
        "    iteration_counter += 1\n",
        "\n",
        "    if iteration_counter > max_iterations:\n",
        "        print(\"\\n⚠️ Iteration cap exceeded. Stopping download.\")\n",
        "        break\n",
        "\n",
        "    try:\n",
        "        label = item['label']\n",
        "        image = item.get('image', None) # Safely attempt to get the image\n",
        "\n",
        "        # Safety 1: The Null Check\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Safety 2: Handle Integer Labels\n",
        "        if isinstance(label, int):\n",
        "            label = 'real' if label == 0 else 'fake'\n",
        "\n",
        "        if label not in ['real', 'fake']:\n",
        "            continue\n",
        "\n",
        "        # Safety 3: Force RGB format\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        if label == 'real' and real_count < TARGET_BUFFER:\n",
        "            image.save(os.path.join(local_real, f\"raw_openfake_real_{real_count}.jpg\"))\n",
        "            real_count += 1\n",
        "            if real_count % 1000 == 0:\n",
        "                print(f\"  -> Downloaded {real_count} / {TARGET_BUFFER} Real images...\")\n",
        "\n",
        "        elif label == 'fake' and fake_count < TARGET_BUFFER:\n",
        "            image.save(os.path.join(local_fake, f\"raw_openfake_fake_{fake_count}.jpg\"))\n",
        "            fake_count += 1\n",
        "            if fake_count % 1000 == 0:\n",
        "                print(f\"  -> Downloaded {fake_count} / {TARGET_BUFFER} Fake images...\")\n",
        "\n",
        "        if real_count == TARGET_BUFFER and fake_count == TARGET_BUFFER:\n",
        "            break\n",
        "\n",
        "    except Exception as e:\n",
        "        save_errors += 1\n",
        "        print(f\"Error at iteration {iteration_counter}: {e}\")\n",
        "\n",
        "print(\"\\n=== Download Summary ===\")\n",
        "print(f\"Real images saved locally: {real_count}\")\n",
        "print(f\"Fake images saved locally: {fake_count}\")\n",
        "print(f\"Save errors: {save_errors}\")\n",
        "\n",
        "# 6. Move to Google Drive\n",
        "print(\"\\nMoving files from local storage to Google Drive. Please wait...\")\n",
        "drive_base = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/raw_data'\n",
        "drive_real = os.path.join(drive_base, 'real')\n",
        "drive_fake = os.path.join(drive_base, 'fake')\n",
        "\n",
        "os.makedirs(drive_real, exist_ok=True)\n",
        "os.makedirs(drive_fake, exist_ok=True)\n",
        "\n",
        "# Copy everything over\n",
        "shutil.copytree(local_real, drive_real, dirs_exist_ok=True)\n",
        "shutil.copytree(local_fake, drive_fake, dirs_exist_ok=True)\n",
        "\n",
        "# 7. Purge Local Temp Files\n",
        "print(\"Cleaning up temporary local files to free space...\")\n",
        "shutil.rmtree(local_base)\n",
        "\n",
        "print(\" Mass download, Drive transfer, and cleanup completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 02.1 - Running RetinaFace Bouncer Script on OpenFake Data."
      ],
      "metadata": {
        "id": "sEyJq4oUCS6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PHASE 2 - RetinaFace Bouncer V3.1.1\n",
        "# Load to Colab Local Drive then Offload to Drive.\n",
        "# Live Updates of the Progress.\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from retinaface import RetinaFace\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from tqdm import tqdm  # The real time progress bar\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Bouncer operating on: GPU (RetinaFace V4.3.2 High-Speed + Live Tracking)\\n\")\n",
        "\n",
        "# 1. Define Drive & Local Paths\n",
        "drive_base = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K'\n",
        "local_base = '/content/temp_workspace'\n",
        "\n",
        "drive_raw_real = os.path.join(drive_base, 'raw_data/real')\n",
        "drive_raw_fake = os.path.join(drive_base, 'raw_data/fake')\n",
        "\n",
        "local_raw_real = os.path.join(local_base, 'raw_data/real')\n",
        "local_raw_fake = os.path.join(local_base, 'raw_data/fake')\n",
        "\n",
        "local_hq_real = os.path.join(local_base, 'processed_data/real')\n",
        "local_hq_fake = os.path.join(local_base, 'processed_data/fake')\n",
        "local_reject_real = os.path.join(local_base, 'rejected/real')\n",
        "local_reject_fake = os.path.join(local_base, 'rejected/fake')\n",
        "\n",
        "# 2. Teleport Raw Data to Local SSD for Speed\n",
        "print(\" Step 1: Teleporting raw data from Google Drive to Local SSD (This takes 1-2 mins)...\")\n",
        "os.makedirs(local_base, exist_ok=True)\n",
        "shutil.copytree(drive_raw_real, local_raw_real, dirs_exist_ok=True)\n",
        "shutil.copytree(drive_raw_fake, local_raw_fake, dirs_exist_ok=True)\n",
        "print(\" Local transfer complete! Setting up output folders...\")\n",
        "\n",
        "for path in [local_hq_real, local_hq_fake, local_reject_real, local_reject_fake]:\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "# 3. Blur Detection Function\n",
        "def blur_score(pil_image):\n",
        "    img = np.array(pil_image)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "# 4. RetinaFace Extraction Engine\n",
        "def hq_crop_engine_v4_3(img_path, save_path, reject_path, padding=25, min_face_size=30, min_face_ratio=0.005, blur_threshold=50, confidence_threshold=0.90):\n",
        "    try:\n",
        "        faces = RetinaFace.detect_faces(img_path)\n",
        "        if not isinstance(faces, dict) or len(faces) == 0:\n",
        "            return False, \"No Face Detected\"\n",
        "\n",
        "        largest_area = 0\n",
        "        best_face = None\n",
        "        for face in faces.values():\n",
        "            box = face.get('facial_area', None)\n",
        "            if box is None: continue\n",
        "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
        "            if area > largest_area:\n",
        "                largest_area = area\n",
        "                best_face = face\n",
        "\n",
        "        if best_face is None: return False, \"No Valid Face Found\"\n",
        "\n",
        "        box = best_face['facial_area']\n",
        "        confidence = best_face['score']\n",
        "        if confidence < confidence_threshold: return False, f\"Low Confidence ({confidence:.2f})\"\n",
        "\n",
        "        img_pil = Image.open(img_path).convert('RGB')\n",
        "        width, height = img_pil.size\n",
        "        face_w, face_h = box[2] - box[0], box[3] - box[1]\n",
        "\n",
        "        if face_w < min_face_size or face_h < min_face_size: return False, \"Too Small Pixels\"\n",
        "        if (face_w * face_h) / (width * height) < min_face_ratio: return False, \"Too Small Ratio\"\n",
        "\n",
        "        x_min, y_min = max(0, int(box[0]) - padding), max(0, int(box[1]) - padding)\n",
        "        x_max, y_max = min(width, int(box[2]) + padding), min(height, int(box[3]) + padding)\n",
        "\n",
        "        cropped_img = img_pil.crop((x_min, y_min, x_max, y_max))\n",
        "        blur_val = blur_score(cropped_img)\n",
        "\n",
        "        if blur_val < blur_threshold: return False, \"Blurred\"\n",
        "\n",
        "        cropped_img.save(save_path)\n",
        "        return True, \"Success\"\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "# 5. High-Speed Cleaner with Live Progress Bar\n",
        "def clean_dataset_fast(input_folder, output_folder, reject_folder, label, target_valid=2000):\n",
        "    print(f\"\\n---  Processing {label} Folder (Target: {target_valid}) ---\")\n",
        "\n",
        "    images = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    success, rejected = 0, 0\n",
        "    reasons = {}\n",
        "\n",
        "    # The tqdm wrapper creates the live progress bar\n",
        "    pbar = tqdm(total=target_valid, desc=f\"Extracting {label} Faces\", unit=\"face\")\n",
        "\n",
        "    for name in images:\n",
        "        if success >= target_valid:\n",
        "            break\n",
        "\n",
        "        img_path = os.path.join(input_folder, name)\n",
        "        save_path = os.path.join(output_folder, name)\n",
        "        reject_path = os.path.join(reject_folder, name)\n",
        "\n",
        "        ok, msg = hq_crop_engine_v4_3(img_path, save_path, reject_path)\n",
        "\n",
        "        if ok:\n",
        "            success += 1\n",
        "            pbar.update(1) # Ticks the progress bar forward\n",
        "        else:\n",
        "            rejected += 1\n",
        "            reasons[msg] = reasons.get(msg, 0) + 1\n",
        "            try:\n",
        "                Image.open(img_path).convert('RGB').save(reject_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    pbar.close()\n",
        "    print(f\"\\n STATS for {label}: {success} Valid | {rejected} Rejected\")\n",
        "\n",
        "# 6. Execute the Run\n",
        "clean_dataset_fast(local_raw_real, local_hq_real, local_reject_real, \"REAL\", target_valid=2000)\n",
        "clean_dataset_fast(local_raw_fake, local_hq_fake, local_reject_fake, \"FAKE\", target_valid=2000)\n",
        "\n",
        "# 7. Push Final Data Back to Drive\n",
        "print(\"\\n Step 3: Pushing pristine extracted faces back to Google Drive...\")\n",
        "drive_final_hq = os.path.join(drive_base, 'processed_data_V4_3')\n",
        "shutil.copytree(os.path.join(local_base, 'processed_data'), drive_final_hq, dirs_exist_ok=True)\n",
        "\n",
        "# 8. Clean Up\n",
        "print(\"🧹 Sweeping temporary local files...\")\n",
        "shutil.rmtree(local_base)\n",
        "\n",
        "print(\"\\n OpenFake Phase Complete! 4,000 perfectly balanced images locked into your Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS6GYH-xsZys",
        "outputId": "01642836-14bb-41dc-9517-d6fc720e7273"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bouncer operating on: GPU (RetinaFace V4.3.2 High-Speed + Live Tracking)\n",
            "\n",
            " Step 1: Teleporting raw data from Google Drive to Local SSD (This takes 1-2 mins)...\n",
            " Local transfer complete! Setting up output folders...\n",
            "\n",
            "---  Processing REAL Folder (Target: 2000) ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rExtracting REAL Faces:   0%|          | 0/2000 [00:00<?, ?face/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26-02-27 15:49:41 - Directory /root/.deepface created\n",
            "26-02-27 15:49:41 - Directory /root/.deepface/weights created\n",
            "26-02-27 15:49:41 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "\n",
            "  0%|          | 0.00/119M [00:00<?, ?B/s]\u001b[A\n",
            " 22%|██▏       | 25.7M/119M [00:00<00:00, 256MB/s]\u001b[A\n",
            " 50%|████▉     | 59.2M/119M [00:00<00:00, 302MB/s]\u001b[A\n",
            " 76%|███████▌  | 89.7M/119M [00:00<00:00, 270MB/s]\u001b[A\n",
            "100%|██████████| 119M/119M [00:00<00:00, 268MB/s]\n",
            "Extracting REAL Faces: 100%|██████████| 2000/2000 [20:02<00:00,  1.66face/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " STATS for REAL: 2000 Valid | 1240 Rejected\n",
            "\n",
            "---  Processing FAKE Folder (Target: 2000) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting FAKE Faces: 100%|██████████| 2000/2000 [11:24<00:00,  2.92face/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " STATS for FAKE: 2000 Valid | 1420 Rejected\n",
            "\n",
            " Step 3: Pushing pristine extracted faces back to Google Drive...\n",
            "🧹 Sweeping temporary local files...\n",
            "\n",
            " OpenFake Phase Complete! 4,000 perfectly balanced images locked into your Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 03 - Downloading Data from FF++."
      ],
      "metadata": {
        "id": "M1SrlwCjClqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import subprocess\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "\n",
        "# Unlock Vault\n",
        "print(\"\\nAccessing secure vault...\")\n",
        "TUM_URL = userdata.get('TUM_LINK')\n",
        "if not TUM_URL:\n",
        "    raise ValueError(\" ERROR: 'TUM_LINK' not found in Secrets. Please check the spelling!\")\n",
        "\n",
        "# Fetch Downloader directly from secret TUM link\n",
        "print(\"\\nFetching official TUM downloader script from your secure link...\")\n",
        "urllib.request.urlretrieve(TUM_URL, \"download.py\")\n",
        "\n",
        "# Define Paths\n",
        "temp_base = '/content/ff_temp'\n",
        "drive_base = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/raw_videos'\n",
        "categories = ['original', 'Deepfakes', 'Face2Face', 'FaceSwap', 'NeuralTextures']\n",
        "\n",
        "print(\"\\n Firing up V3.2 auto-bypassing download sequence...\")\n",
        "\n",
        "for cat in categories:\n",
        "    sub_folder = 'real' if cat == 'original' else f'fake/{cat.lower()}'\n",
        "    temp_path = os.path.join(temp_base, sub_folder)\n",
        "    drive_path = os.path.join(drive_base, sub_folder)\n",
        "\n",
        "    shutil.rmtree(temp_path, ignore_errors=True)\n",
        "    os.makedirs(temp_path, exist_ok=True)\n",
        "    os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "    print(f\"\\n Pulling 2 test videos for: {cat} to high-speed local storage...\")\n",
        "\n",
        "    # THE FIX: Echo automatically presses Enter to agree to the TOS\n",
        "    cmd = f'echo \"\" | python3 download.py {temp_path} -d {cat} -c c23 -n 2 --server EU2'\n",
        "    result = subprocess.run(cmd, shell=True)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\" ERROR: Download failed for {cat}. Check server status.\")\n",
        "    else:\n",
        "        print(f\" Download complete. Transferring {cat} to Google Drive...\")\n",
        "        shutil.copytree(temp_path, drive_path, dirs_exist_ok=True)\n",
        "        print(f\" Transfer complete for {cat}.\")\n",
        "\n",
        "print(\"\\n Micro-Test Download Complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRhW9iLZCvsG",
        "outputId": "bc9cdbb2-4fc7-4d23-b09c-44f88be9e2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Accessing secure vault...\n",
            "\n",
            "Fetching official TUM downloader script from your secure link...\n",
            "\n",
            " Firing up V3.2 auto-bypassing download sequence...\n",
            "\n",
            " Pulling 2 test videos for: original to high-speed local storage...\n",
            " Download complete. Transferring original to Google Drive...\n",
            " Transfer complete for original.\n",
            "\n",
            " Pulling 2 test videos for: Deepfakes to high-speed local storage...\n",
            " Download complete. Transferring Deepfakes to Google Drive...\n",
            " Transfer complete for Deepfakes.\n",
            "\n",
            " Pulling 2 test videos for: Face2Face to high-speed local storage...\n",
            " Download complete. Transferring Face2Face to Google Drive...\n",
            " Transfer complete for Face2Face.\n",
            "\n",
            " Pulling 2 test videos for: FaceSwap to high-speed local storage...\n",
            " Download complete. Transferring FaceSwap to Google Drive...\n",
            " Transfer complete for FaceSwap.\n",
            "\n",
            " Pulling 2 test videos for: NeuralTextures to high-speed local storage...\n",
            " Download complete. Transferring NeuralTextures to Google Drive...\n",
            " Transfer complete for NeuralTextures.\n",
            "\n",
            " V Micro-Test Download Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 03.1 - Running the Frame Extracter for the FF++ Vidoes."
      ],
      "metadata": {
        "id": "O8Ka-Wu1Sngf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import cv2\n",
        "import hashlib\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Lock the random seed for perfect reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "drive_raw_base = \"/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/raw_videos\"\n",
        "drive_extract_base = \"/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/extracted_frames_v2\"\n",
        "local_temp_base = \"/content/local_processing\"\n",
        "\n",
        "target_frames_with_buffer = 7\n",
        "split_ratios = {\"train\": 0.70, \"val\": 0.15, \"test\": 0.15}\n",
        "\n",
        "os.makedirs(local_temp_base, exist_ok=True)\n",
        "local_video_path = os.path.join(local_temp_base, \"processing_vid.mp4\")\n",
        "\n",
        "# Initialize Traceability Log\n",
        "log_file_path = \"/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/split_log.txt\"\n",
        "with open(log_file_path, \"w\") as f:\n",
        "    f.write(\"FF++ Video Split and Extraction Log\\n\")\n",
        "    f.write(\"===================================\\n\")\n",
        "\n",
        "def extract_buffered_frames(video_path, output_folder, category_prefix, n_frames):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if total_frames < n_frames:\n",
        "        cap.release()\n",
        "        return 0, total_frames\n",
        "\n",
        "    step = total_frames // n_frames\n",
        "    start_offset = random.randint(0, max(0, step - 1))\n",
        "    target_ids = set([start_offset + (i * step) for i in range(n_frames)])\n",
        "\n",
        "    vid_name = os.path.basename(video_path).split('.')[0]\n",
        "\n",
        "    # Generate a short hash to absolutely prevent filename collisions\n",
        "    short_hash = hashlib.md5(video_path.encode()).hexdigest()[:6]\n",
        "\n",
        "    extracted_count = 0\n",
        "    current_id = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret = cap.grab()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if current_id in target_ids:\n",
        "            ret, frame = cap.retrieve()\n",
        "            if ret:\n",
        "                frame_name = f\"{category_prefix}_{vid_name}_{short_hash}_f{extracted_count:03d}.jpg\"\n",
        "                save_path = os.path.join(output_folder, frame_name)\n",
        "                cv2.imwrite(save_path, frame)\n",
        "                extracted_count += 1\n",
        "\n",
        "        current_id += 1\n",
        "        if extracted_count >= n_frames:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    return extracted_count, total_frames\n",
        "\n",
        "print(\"Initiating reproducible extraction sequence...\")\n",
        "categories = ['real', 'fake/deepfakes', 'fake/face2face', 'fake/faceswap', 'fake/neuraltextures']\n",
        "\n",
        "total_extracted = 0\n",
        "skipped_videos = 0\n",
        "\n",
        "for cat in categories:\n",
        "    cat_path = os.path.join(drive_raw_base, cat)\n",
        "    videos = glob.glob(os.path.join(cat_path, \"**\", \"*.mp4\"), recursive=True)\n",
        "\n",
        "    if not videos:\n",
        "        continue\n",
        "\n",
        "    random.shuffle(videos)\n",
        "\n",
        "    train_split = int(len(videos) * split_ratios[\"train\"])\n",
        "    val_split = int(len(videos) * (split_ratios[\"train\"] + split_ratios[\"val\"]))\n",
        "\n",
        "    splits = {\n",
        "        \"train\": videos[:train_split],\n",
        "        \"val\": videos[train_split:val_split],\n",
        "        \"test\": videos[val_split:]\n",
        "    }\n",
        "\n",
        "    for split_name, split_videos in splits.items():\n",
        "        if not split_videos:\n",
        "            continue\n",
        "\n",
        "        cat_safe_name = cat.replace('/', '_')\n",
        "        final_drive_folder = os.path.join(drive_extract_base, split_name, cat_safe_name)\n",
        "        os.makedirs(final_drive_folder, exist_ok=True)\n",
        "\n",
        "        pbar = tqdm(total=len(split_videos), desc=f\"{split_name.upper()} - {cat_safe_name}\", unit=\"vid\")\n",
        "\n",
        "        with open(log_file_path, \"a\") as log:\n",
        "            for video_path in split_videos:\n",
        "                # Overwrite directly to local SSD for maximum IO speed\n",
        "                shutil.copy2(video_path, local_video_path)\n",
        "\n",
        "                frames_saved, total_found = extract_buffered_frames(local_video_path, final_drive_folder, f\"{split_name}_{cat_safe_name}\", target_frames_with_buffer)\n",
        "\n",
        "                if frames_saved == 0:\n",
        "                    skipped_videos += 1\n",
        "                    log.write(f\"[SKIPPED] {video_path} (Only {total_found} frames)\\n\")\n",
        "                else:\n",
        "                    total_extracted += frames_saved\n",
        "                    log.write(f\"[{split_name.upper()}] {video_path} -> Extracted {frames_saved} frames\\n\")\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "shutil.rmtree(local_temp_base, ignore_errors=True)\n",
        "print(f\"\\nExtraction complete. {total_extracted} frames stored.\")\n",
        "print(f\"{skipped_videos} short videos skipped. Check split_log.txt for full traceability.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmsUfhlxZnHb",
        "outputId": "a646ea3f-d3a8-48e8-a28e-20c0f54db2f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initiating reproducible extraction sequence...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN - real: 100%|██████████| 1/1 [00:02<00:00,  2.33s/vid]\n",
            "TEST - real: 100%|██████████| 1/1 [00:02<00:00,  2.43s/vid]\n",
            "TRAIN - fake_deepfakes: 100%|██████████| 1/1 [00:02<00:00,  2.14s/vid]\n",
            "TEST - fake_deepfakes: 100%|██████████| 1/1 [00:03<00:00,  3.71s/vid]\n",
            "TRAIN - fake_face2face: 100%|██████████| 1/1 [00:03<00:00,  3.04s/vid]\n",
            "TEST - fake_face2face: 100%|██████████| 1/1 [00:02<00:00,  2.18s/vid]\n",
            "TRAIN - fake_faceswap: 100%|██████████| 1/1 [00:02<00:00,  2.20s/vid]\n",
            "TEST - fake_faceswap: 100%|██████████| 1/1 [00:02<00:00,  2.18s/vid]\n",
            "TRAIN - fake_neuraltextures: 100%|██████████| 1/1 [00:02<00:00,  2.22s/vid]\n",
            "TEST - fake_neuraltextures: 100%|██████████| 1/1 [00:03<00:00,  3.38s/vid]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extraction complete. 70 frames stored.\n",
            "0 short videos skipped. Check split_log.txt for full traceability.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phase 03.2 - Running the RetinaFace on Extracted Frames."
      ],
      "metadata": {
        "id": "02Zl-KMpbpQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import glob\n",
        "import csv\n",
        "import imagehash\n",
        "import random\n",
        "from retinaface import RetinaFace\n",
        "from PIL import Image\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 1. Global Determinism\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Master Bouncer Operating On: GPU (Hamming Dist pHash + Single I/O + BBox Logging)\\n\")\n",
        "\n",
        "drive_input_base = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/extracted_frames_v2'\n",
        "drive_output_base = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/processed_faces_v2'\n",
        "drive_reject_base = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/rejected_faces_v2'\n",
        "csv_log_path = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/extraction_log_v2.csv'\n",
        "\n",
        "local_base = '/content/temp_workspace'\n",
        "local_input = os.path.join(local_base, 'input_frames')\n",
        "local_output = os.path.join(local_base, 'processed_faces')\n",
        "local_reject = os.path.join(local_base, 'rejected_faces')\n",
        "\n",
        "print(\"Teleporting buffered frames to Local SSD...\")\n",
        "shutil.rmtree(local_base, ignore_errors=True)\n",
        "shutil.copytree(drive_input_base, local_input, dirs_exist_ok=True)\n",
        "\n",
        "with open(csv_log_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Image_Name\", \"Split\", \"Category\", \"Status\", \"Reason\", \"Confidence\", \"Blur_Score\", \"pHash\", \"Bounding_Box\"])\n",
        "\n",
        "# Store actual hash objects for fast Hamming distance calculation\n",
        "seen_hashes = []\n",
        "\n",
        "def master_crop_engine(img_path, save_path, padding=25, min_face_size=30, min_face_ratio=0.005, blur_threshold=25, confidence_threshold=0.90):\n",
        "    try:\n",
        "        # 5. Single I/O Load: Read once with OpenCV\n",
        "        img_cv = cv2.imread(img_path)\n",
        "        if img_cv is None:\n",
        "            return False, \"Corrupted Image\", 0.0, 0.0, \"\", \"[]\"\n",
        "\n",
        "        height, width = img_cv.shape[:2]\n",
        "\n",
        "        # RetinaFace accepts NumPy arrays directly\n",
        "        faces = RetinaFace.detect_faces(img_cv)\n",
        "        if not isinstance(faces, dict) or len(faces) == 0:\n",
        "            return False, \"No Face Detected\", 0.0, 0.0, \"\", \"[]\"\n",
        "\n",
        "        largest_area = 0\n",
        "        best_face = None\n",
        "        for face in faces.values():\n",
        "            box = face.get('facial_area', None)\n",
        "            if box is None: continue\n",
        "            area = (box[2] - box[0]) * (box[3] - box[1])\n",
        "            if area > largest_area:\n",
        "                largest_area = area\n",
        "                best_face = face\n",
        "\n",
        "        if best_face is None:\n",
        "            return False, \"No Valid Face Found\", 0.0, 0.0, \"\", \"[]\"\n",
        "\n",
        "        box = best_face['facial_area']\n",
        "        str_box = f\"[{box[0]}, {box[1]}, {box[2]}, {box[3]}]\"\n",
        "        confidence = best_face['score']\n",
        "\n",
        "        if confidence < confidence_threshold:\n",
        "            return False, \"Low Confidence\", confidence, 0.0, \"\", str_box\n",
        "\n",
        "        face_w, face_h = box[2] - box[0], box[3] - box[1]\n",
        "\n",
        "        # 3. Reintroduced Face-to-Frame Ratio Filter\n",
        "        if face_w < min_face_size or face_h < min_face_size:\n",
        "            return False, \"Resolution Too Small\", confidence, 0.0, \"\", str_box\n",
        "        if (face_w * face_h) / (width * height) < min_face_ratio:\n",
        "            return False, \"Face Ratio Too Small\", confidence, 0.0, \"\", str_box\n",
        "\n",
        "        # Fast NumPy cropping\n",
        "        x_min, y_min = max(0, int(box[0]) - padding), max(0, int(box[1]) - padding)\n",
        "        x_max, y_max = min(width, int(box[2]) + padding), min(height, int(box[3]) + padding)\n",
        "        cropped_cv = img_cv[y_min:y_max, x_min:x_max]\n",
        "\n",
        "        # Calculate blur on the cropped NumPy array\n",
        "        gray_crop = cv2.cvtColor(cropped_cv, cv2.COLOR_BGR2GRAY)\n",
        "        blur_val = cv2.Laplacian(gray_crop, cv2.CV_64F).var()\n",
        "\n",
        "        if blur_val < blur_threshold:\n",
        "            return False, \"Motion Blur Detected\", confidence, blur_val, \"\", str_box\n",
        "\n",
        "        # Convert to PIL ONLY for the final resize and hash\n",
        "        cropped_pil = Image.fromarray(cv2.cvtColor(cropped_cv, cv2.COLOR_BGR2RGB))\n",
        "        standardized_img = cropped_pil.resize((224, 224), Image.BICUBIC)\n",
        "\n",
        "        # 2. Upgraded pHash Logic (Hamming Distance <= 5)\n",
        "        new_hash = imagehash.phash(standardized_img)\n",
        "\n",
        "        for existing_hash in seen_hashes:\n",
        "            if new_hash - existing_hash <= 2:\n",
        "                return False, \"Duplicate Face (Hamming Dist <= 2)\", confidence, blur_val, str(new_hash), str_box\n",
        "\n",
        "        seen_hashes.append(new_hash)\n",
        "\n",
        "        standardized_img.save(save_path, format='JPEG', quality=95)\n",
        "        return True, \"Accepted\", confidence, blur_val, str(new_hash), str_box\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, f\"Engine Error: {str(e)}\", 0.0, 0.0, \"\", \"[]\"\n",
        "\n",
        "print(\"Firing up RetinaFace Deduplication Engine...\")\n",
        "image_files = glob.glob(os.path.join(local_input, \"**\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "if not image_files:\n",
        "    print(\"ERROR: No images found in local storage.\")\n",
        "else:\n",
        "    success_count, reject_count = 0, 0\n",
        "    pbar = tqdm(total=len(image_files), desc=\"Processing Frames\", unit=\"img\")\n",
        "\n",
        "    with open(csv_log_path, mode='a', newline='') as log_file:\n",
        "        csv_writer = csv.writer(log_file)\n",
        "\n",
        "        for img_path in image_files:\n",
        "            relative_path = os.path.relpath(os.path.dirname(img_path), local_input)\n",
        "            path_parts = relative_path.split(os.sep)\n",
        "            split_name = path_parts[0] if len(path_parts) > 0 else \"unknown\"\n",
        "            cat_name = path_parts[1] if len(path_parts) > 1 else \"unknown\"\n",
        "\n",
        "            out_folder = os.path.join(local_output, relative_path)\n",
        "            rej_folder = os.path.join(local_reject, relative_path)\n",
        "            os.makedirs(out_folder, exist_ok=True)\n",
        "            os.makedirs(rej_folder, exist_ok=True)\n",
        "\n",
        "            file_name = os.path.basename(img_path)\n",
        "            save_path = os.path.join(out_folder, file_name)\n",
        "            reject_path = os.path.join(rej_folder, file_name)\n",
        "\n",
        "            passed, msg, conf, blur, phash_val, bbox = master_crop_engine(img_path, save_path)\n",
        "\n",
        "            # 4. Store Bounding Boxes in CSV\n",
        "            if passed:\n",
        "                success_count += 1\n",
        "                csv_writer.writerow([file_name, split_name, cat_name, \"Accepted\", \"None\", round(conf, 4), round(blur, 2), phash_val, bbox])\n",
        "            else:\n",
        "                reject_count += 1\n",
        "                csv_writer.writerow([file_name, split_name, cat_name, \"Rejected\", msg, round(conf, 4), round(blur, 2), phash_val, bbox])\n",
        "                try:\n",
        "                    Image.open(img_path).convert('RGB').save(reject_path, format='JPEG', quality=95)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    print(\"\\n--- BOUNCER STATS ---\")\n",
        "    print(f\"Pristine Faces Secured: {success_count}\")\n",
        "    print(f\"Frames Rejected: {reject_count}\")\n",
        "\n",
        "print(\"Pushing standardized dataset and CSV logs back to Google Drive...\")\n",
        "shutil.copytree(local_output, drive_output_base, dirs_exist_ok=True)\n",
        "shutil.copytree(local_reject, drive_reject_base, dirs_exist_ok=True)\n",
        "shutil.rmtree(local_base, ignore_errors=True)\n",
        "\n",
        "print(\"Pipeline Complete! Check extraction_log_v2.csv for full traceability.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWQz6DtXHqgj",
        "outputId": "91db54b2-320a-4d09-a32c-756ac171f193"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Master Bouncer Operating On: GPU (Hamming Dist pHash + Single I/O + BBox Logging)\n",
            "\n",
            "Teleporting buffered frames to Local SSD...\n",
            "Firing up RetinaFace Deduplication Engine...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Frames: 100%|██████████| 70/70 [00:16<00:00,  4.32img/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- BOUNCER STATS ---\n",
            "Pristine Faces Secured: 53\n",
            "Frames Rejected: 17\n",
            "Pushing standardized dataset and CSV logs back to Google Drive...\n",
            "Pipeline Complete! Check extraction_log_v2.csv for full traceability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Stats from RetinaFace Extraction"
      ],
      "metadata": {
        "id": "JmkVFzhQQgPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/Deepfake_Honours_Project/Sandbox_10K/FF_Plus/Test_Run/extraction_log_v2.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"--- BOUNCER REJECTION BREAKDOWN ---\")\n",
        "rejections = df[df['Status'] == 'Rejected']\n",
        "print(rejections['Reason'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A8PGpzjMzTC",
        "outputId": "7bf68090-ff27-4ad3-b42b-453af8ec71d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BOUNCER REJECTION BREAKDOWN ---\n",
            "Reason\n",
            "Duplicate Face (Hamming Dist <= 2)    14\n",
            "Motion Blur Detected                   3\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}